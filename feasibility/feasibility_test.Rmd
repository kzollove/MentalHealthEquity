# Executive Summary 

**Author:** Jacob Scott Zelko

**Date:** 2022-11-02

**Summary:** A feasibility assessment to assess candidacy of partner site location 

# Environment Set-Up

## R and RStudio Requirements

For this feasibility assessment, you will need: 

- **R version 4.2.1**
	- [Windows](https://cran.r-project.org/bin/windows/base/old/4.2.1/)
		- [Install R 4.2.1](https://cran.r-project.org/bin/windows/base/old/4.2.1/R-4.2.1-win.exe)
	- [Mac OSX Big Sur](https://cran.r-project.org/bin/macosx/big-sur-arm64/base/)
	  	- [Install R 4.2.1](https://cran.r-project.org/bin/macosx/big-sur-arm64/base/R-4.2.1-arm64.pkg)
	- [Linux](https://cran.r-project.org/src/base/R-4/)
	  	- [Install R 4.2.1](https://cran.r-project.org/src/base/R-4/R-4.2.1.tar.gz)
- [**RStudio**](https://posit.co/download/rstudio-desktop/)

Furthermore, **I am assuming that RStudio is the client being used** for this assessment.
As RStudio can be configured very differently depending on what sort of operating system you are using, please see this [RStudio guide on how to switch the version of R being used in RStudio](https://support.rstudio.com/hc/en-us/articles/200486138-Changing-R-versions-for-the-RStudio-Desktop-IDE).

> **NOTE:** If you do not want to manually deal with multiple versions of R on your system, I suggest checking out the great Rust tool, [rig](https://github.com/r-lib/rig) which allows you to have multiple R versions on the same machine simultaneously and switch between them seamlessly.

## Copying the `MentalHealthEquity` Project

To download the environment we will use, there are two procedures available:

### Git Command Line Approach

Assuming you have some experience with the fantastic version control tool, [git](https://git-scm.com), and some experience with the command line (whether on Windows, Linux, or OSX) you can follow these steps:

1. Navigate to a directory of your choice
2. Execute the following git command: 
   - `git clone git@github.com:ohdsi-studies/MentalHealthEquity.git`

### Website Approach

For this approach, you will need to: 

1. Go to this [link](https://github.com/ohdsi-studies/MentalHealthEquity)
2. Follow the directions [on downloading a repository without git here](https://sites.northwestern.edu/researchcomputing/resources/downloading-from-github/#:~:text=When%20downloading%20materials%20to%20your,repository%20as%20a%20ZIP%20file.) 
3. Unzip the zip file you downloaded to somewhere you want 

## Configuring R Environment

For this tutorial, you will need the `renv` package installed into your main R environment (for more information about this package, refer to the [Appendix](#appendix)).
This can be done via: 

```{r, eval = FALSE}
install.packages("renv")
```

Then, from within RStudio, navigate to the folder `MentalHealthEquity/feasibility`.
Within that directory, do the following steps within the RStudio console: 

1. Load the RStudio project within the `MentalHealthEquity/feasibility` folder 
2. Load the `renv` package: `library(renv)` 
3. Activate the `renv` environment: `renv::activate()`
4. Restore the needed project packages by running: `renv::restore()` and accepting 

The following code block shows how this would run:

```{r, eval = FALSE, message = FALSE, warning = FALSE}
library(renv)

renv::activate()
renv::restore()
```

If everything worked correctly up to this point, you should be prepared to run the feasibility assessment!

> **NOTE:** For steps 2, 3 and 4, RStudio may have already done or attempted to do this for you. If it did, you may not see anything when you run these steps in the console.

# Running Feasbility Assessment

## Packages 

The following packages will be loaded to conduct the feasibility assessment:

```{r, eval = FALSE, message = FALSE}
library(DatabaseConnector)
library(dplyr)
library(ggplot2)
library(lubridate)
library(readr)
library(SqlRender)
library(tibble)
```

To learn more about these packages, see the [Appendix](#appendix).

## Defining Connection Details

Here, we need to set-up connection to the OMOP CDM database we will assess.
To do so, we need to define some constants that will be used for the connection.
The following list of constants:

- `dbms` - the database management system that is used to host your database; common options include (see all options [here](http://ohdsi.github.io/DatabaseConnector/reference/createConnectionDetails.html)):
	- `"postgresql"`
	- `"sql server"`
- `server` - name of the server; could be `localhost`, an address like `123.0.1.5`, etc. 
- `user` - your username to access the server 
- `password` - the password you use to access the server 
- `port` - the port where the database is hosted
- `schema` - name of the database schema used

Must be defined in this code block (change `eval = FALSE` to `eval = FALSE` when you have set these variables correctly): 

```{r, eval = FALSE}
dbms <- "Fill in here"
server <- "Fill in here"
user <- "Fill in here"
password <- "Fill in here"
port <- "Fill in here"
schema <- "Fill in here"
```

An additional step needed is to configure the required driver to connect to the database as follows: 

1. Determine the name of your database management system based on the list [here](http://ohdsi.github.io/DatabaseConnector/reference/downloadJdbcDrivers.html)
2. Download the drivers by running the following:

This is accomplished in the following codeblock (change `eval = FALSE` to `eval = FALSE` when you have set these variables correctly):
	
```{r, eval = FALSE}
pathToDriver = "/location/that/you/want"
downloadJdbcDrivers(dbms = dbms, pathToDriver = pathToDriver, method = "auto")
```

Once this is done, we can create the connection to the database (change `eval = FALSE` to `eval = FALSE` when you have set these variables correctly): 

```{r, eval = FALSE} 
connectionDetails <- createConnectionDetails(dbms=dbms, 
                                             server=server,
                                             user=user,
                                             password=password,
					     port=port,
					     pathToDriver=pathToDriver)

connection <- connect(connectionDetails)
```

If there were no errors, then we should be able to continue with the analysis! 

> WARN: As you proceed with this analysis, if you encounter a Java issue like this: "Insufficient java heap memory", please run the following code block:
> 
> ````{r, eval = FALSE}
> options(java.parameters = c("-XX:+UseConcMarkSweepGC", "-Xmx8192m"))
> ````
> This is only an emergency work around and should be removed when a better solution is found.

### Example Connection 

If any of this was confusing, here is an example of how to fill out the above connection information:

```{r, eval = FALSE}
dbms <- "postgresql"
server <- "test.data.americus.edu/mimic_omop"
user <- "mimic"
password <- "omoprocks"
port <- 5042
schema <- "mimic.omop"

pathToDriver = "utils"
downloadJdbcDrivers(dbms = dbms, pathToDriver = pathToDriver, method = "auto")

connectionDetails <- createConnectionDetails(dbms=dbms, 
                                             server=server,
                                             user=user,
                                             password=password,
					     port=port,
					     pathToDriver=pathToDriver)

connection <- connect(connectionDetails)
```

## Queries

There are a number of queries to execute that will take varying amounts of time depending on how many patients are in your database and how much data is at your site.

### Person Query

**Desc:** Gets all unique person IDs.

```{r, eval = FALSE}
person_sql <- render(
	'SELECT DISTINCT "PERSON_1"."person_id"
	FROM @schema."person" AS "PERSON_1";',
	schema = schema) 
person_sql <- translate(sql = person_sql, targetDialect = dbms)

person_ids <- querySql(connection, person_sql)
person_ids <- person_ids$PERSON_ID
```

### Person Race Query

**Desc:** Gets race ID's associated with each person ID passed into this query

```{r, eval = FALSE}
person_race_sql <- render(
		'SELECT
		  "PERSON_1"."person_id",
		  "PERSON_1"."race_concept_id"
		FROM @schema."person" AS "PERSON_1"
		WHERE ("PERSON_1"."person_id" IN (@ids));',
		schema = schema, ids = person_ids)
person_race_sql <- translate(sql = person_race_sql, targetDialect = dbms)

person_races <- querySql(connection, person_race_sql)
```

### Person Gender Query

**Desc:** Gets gender ID's associated with each person ID passed into this query

```{r, eval = FALSE}
person_gender_sql <- render(
		'SELECT
		  "PERSON_1"."person_id",
		  "PERSON_1"."gender_concept_id"
		FROM @schema."person" AS "PERSON_1"
		WHERE ("PERSON_1"."person_id" IN (@ids));',
		schema = schema, ids = person_ids)
person_gender_sql <- translate(sql = person_gender_sql, targetDialect = dbms)

person_genders <- querySql(connection, person_gender_sql)
```

### Person Age Group Query

**Desc:** Gets an age group associated with each person ID passed into this query. 
For the purpose of this analysis, the subtrahend value is calculated based on the latest recorded date found in the `observation_period` table (considered by OHDSI experts to be the table with the latest information in a database).

```{r, eval = FALSE} 
db_year_range_sql <- render(
'SELECT
  MIN("observation_period_1"."observation_period_end_date") AS "first_year",
  MAX("observation_period_1"."observation_period_end_date") AS "last_year"
FROM @schema."observation_period" AS "observation_period_1";',
schema = schema)
db_year_range_sql <- translate(sql = db_year_range_sql, targetDialect = dbms)

db_year_range <- querySql(connection, db_year_range_sql)

# Determine earliest year data is recorded for
first_year <- db_year_range$FIRST_YEAR %>% 
	as.character %>%
	parse_datetime("%Y-%m-%d") %>%
	year

# Determine latest year data is recorded for
last_year <- db_year_range$LAST_YEAR %>% 
	as.character %>%
	parse_datetime("%Y-%m-%d") %>%
	year

person_age_groups_sql <- render(
		'SELECT
  "PERSON_2"."person_id",
  (CASE WHEN ("PERSON_2"."age" < 10) THEN \'0 - 9\' WHEN ("PERSON_2"."age" < 20) THEN \'10 - 19\' WHEN ("PERSON_2"."age" < 30) THEN \'20 - 29\' WHEN ("PERSON_2"."age" < 40) THEN \'30 - 39\' WHEN ("PERSON_2"."age" < 50) THEN \'40 - 49\' WHEN ("PERSON_2"."age" < 60) THEN \'50 - 59\' WHEN ("PERSON_2"."age" < 70) THEN \'60 - 69\' WHEN ("PERSON_2"."age" < 80) THEN \'70 - 79\' WHEN ("PERSON_2"."age" < 90) THEN \'80 - 89\' END) AS "age_group"
FROM (
  SELECT
    "PERSON_1"."person_id",
    (@subtrahend - "PERSON_1"."year_of_birth") AS "age"
  FROM @schema."person" AS "PERSON_1"
  WHERE ("PERSON_1"."person_id" IN (@ids))
) AS "PERSON_2";',
		schema = schema, ids = person_ids, subtrahend = 2022)
person_age_groups_sql <- translate(sql = person_age_groups_sql, targetDialect = dbms)

person_age_groups <- querySql(connection, person_age_groups_sql)
```

### Stratified Person Query 

**Desc:** A compact query to get all persons by race, gender, and age group (thanks to Sarah Gasman for the suggestion!). 
For the purpose of this analysis, the subtrahend value is calculated based on the latest recorded date found in the `observation_period` table (considered by OHDSI experts to be the table with the latest information in a database).

```{r}
db_year_range_sql <- render(
'SELECT
  MIN("observation_period_1"."observation_period_end_date") AS "first_year",
  MAX("observation_period_1"."observation_period_end_date") AS "last_year"
FROM @schema."observation_period" AS "observation_period_1";',
schema = schema)
db_year_range_sql <- translate(sql = db_year_range_sql, targetDialect = dbms)

db_year_range <- querySql(connection, db_year_range_sql)

# Determine earliest year data is recorded for
first_year <- db_year_range$FIRST_YEAR %>% 
	as.character %>%
	parse_datetime("%Y-%m-%d") %>%
	year

# Determine latest year data is recorded for
last_year <- db_year_range$LAST_YEAR %>% 
	as.character %>%
	parse_datetime("%Y-%m-%d") %>%
	year

person_stratified_sql <- render(
                             'SELECT
                             COUNT(DISTINCT ages.person_id) as counts,
                             ages.race_concept_id,
                             ages.gender_concept_id,
                             ages.age_group
                             FROM (SELECT
  "PERSON_2"."person_id",
  (CASE WHEN ("PERSON_2"."age" < 10) THEN \'0 - 9\' WHEN ("PERSON_2"."age" < 20) THEN \'10 - 19\' WHEN ("PERSON_2"."age" < 30) THEN \'20 - 29\' WHEN ("PERSON_2"."age" < 40) THEN \'30 - 39\' WHEN ("PERSON_2"."age" < 50) THEN \'40 - 49\' WHEN ("PERSON_2"."age" < 60) THEN \'50 - 59\' WHEN ("PERSON_2"."age" < 70) THEN \'60 - 69\' WHEN ("PERSON_2"."age" < 80) THEN \'70 - 79\' WHEN ("PERSON_2"."age" < 90) THEN \'80 - 89\' END) AS "age_group",
  "PERSON_2"."race_concept_id",
  "PERSON_2"."gender_concept_id"
FROM (SELECT
    "PERSON_1"."person_id",
    (@subtrahend - "PERSON_1"."year_of_birth") AS "age",
    "PERSON_1"."race_concept_id" AS "race_concept_id",
    "PERSON_1"."gender_concept_id" AS "gender_concept_id"
  FROM @schema.person AS "PERSON_1") AS "PERSON_2") ages
GROUP BY ages.age_group,ages.race_concept_id, ages.gender_concept_id;', schema = schema, subtrahend = last_year)

person_stratified_sql <- translate(sql = person_stratified_sql, targetDialect = dbms)
 
person_stratified <- querySql(connection, person_stratified_sql)
```

### Care Site Query

**Desc:** Gets counts of distinct care site types present in database:

```{r, eval = FALSE}
care_sites_sql <- render('
SELECT 
     foo.care_site_id,
     care_site.place_of_service_concept_id,
     COUNT(foo.care_site_id) AS "counts"
FROM 
        (
		SELECT DISTINCT
			person_id, care_site_id
		FROM 
                        @schema.visit_occurrence
	) foo
FULL OUTER JOIN 
	@schema.care_site
ON 
	foo.care_site_id = care_site.care_site_id
GROUP BY 
	foo.care_site_id,
	care_site.place_of_service_concept_id;', schema = schema)
care_sites_sql <- translate(sql = care_sites_sql, targetDialect = dbms)

care_sites <- querySql(connection, care_sites_sql)
```

### State Person Query

**Desc:** Gets counts of persons broken down by state:

```{r, eval = FALSE}
location_sql <- render('SELECT
  "LOCATION_2"."state",
  COUNT("LOCATION_2"."state") AS COUNT
FROM (
  SELECT
    "LOCATION_1"."location_id",
    "LOCATION_1"."state"
  FROM @schema.location AS "LOCATION_1"
) AS "LOCATION_2"
JOIN person AS "PERSON_1" ON ("LOCATION_2"."location_id" = "PERSON_1"."location_id")
GROUP BY "LOCATION_2".state;', schema = schema)
location_sql <- translate(sql = location_sql, targetDialect = dbms)

location <- querySql(connection, location_sql)
```

### Visit Type Query 

**Desc:** Count of unique visits across types of visits

```{r, eval = FALSE}
visit_types_sql <- render('SELECT
	visit_concept_id, 
	COUNT(visit_concept_id) 
FROM (
	SELECT DISTINCT 
		person_id,
		visit_concept_id
	FROM
		@schema.visit_occurrence 
	) tmp
GROUP BY 
	visit_concept_id;', schema = schema)
visit_types_sql <- translate(sql = visit_types_sql, targetDialect = dbms)

visit_types <- querySql(connection, visit_types_sql)
```

## Analyses to Conduct

### Breakdown by Race, Gender, and Age Group

Here, we look at breakdowns by race, gender, and age group of persons.

#### Aggregation and Privacy Preserving

Now we enforce aggregation and [HITECH standards](https://www.hhs.gov/hipaa/for-professionals/special-topics/hitech-act-enforcement-interim-final-rule/index.html) for filtering:

```{r, eval = FALSE}
person_stratified_counts <- person_stratified %>% 
filter(counts> 10)
```

#### Export 

Now, all we need to do is export the data: 

```{r, eval = FALSE}
write.table(person_stratified_counts, file = "data/exp_raw/person_stratified_breakdown.csv")
```

### Breakdown by Care Site 

For this, all we need to do is export the data: 

```{r, eval = FALSE}
write.table(care_sites, file = "data/exp_raw/care_site_breakdown.csv")
```

### Breakdown by Visit Type 

For this, all we need to do is export the data: 

```{r, eval = FALSE}
write.table(visit_types, file = "data/exp_raw/visit_type_breakdown.csv")
```

### Breakdown by State

#### Enforce Privacy 

Here we must enforce [HITECH standards](https://www.hhs.gov/hipaa/for-professionals/special-topics/hitech-act-enforcement-interim-final-rule/index.html) for filtering:

```{r, eval = FALSE}
location <- location %>% 
filter(COUNT > 10)
```

#### Export 

Now, all we need to do is export the data: 

```{r, eval = FALSE}
write.table(location, file = "data/exp_raw/location_breakdown.csv")
```

# Conclusion

## Next Steps

With this feasibility analysis done, please share the results back to us at GTRI. 
Feel free to contact us at `jacob.zelko@gtri.gatech.edu` and we can discuss further steps.

## THANK YOU! 

If you completed this entire feasibility assessment, **THANK YOU**! 
You are making this network study possible and my team and I at GTRI fully understand how difficult getting these assessments to run can be!
We look forward to collaborating further!

# Appendix 

## Packages Details

- [`renv`](https://rstudio.github.io/renv/index.html) - create reproducible environments for R projects
- [`ggplot2`](https://ggplot2.tidyverse.org) - system for declaratively creating graphics
- [`dplyr`](https://dplyr.tidyverse.org) - grammar for data manipulation
- [`tibble`](https://tibble.tidyverse.org) - improved data.frame functionality
- [`SqlRender`](https://ohdsi.github.io/SqlRender/) - package for rendering parameterized SQL
- [`DatabaseConnector`](http://ohdsi.github.io/DatabaseConnector/) - package for connecting to databases using JDBC

TODO: Update packages used list
